{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After IDL tracking, this notebook collects track files, does preprocessing (removing outliers, filling in missing values, cropping times)\n",
    "\n",
    "1. Run this block to set up \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ht2.utils import *\n",
    "from ht2.quant import *\n",
    "from ht2.qc import *\n",
    "from ht2.io_handler import *\n",
    "import shutil as sh\n",
    "import pandas as pd\n",
    "\n",
    "g_template = \"{cell}G_{reg}ot{spot}_t{len}.{extension}\"\n",
    "r_template = \"{cell}R_{reg}ot{spot}_t{len}.{extension}\"\n",
    "\n",
    "def batch_read_tracks(f_list, \n",
    "    trk_template\n",
    "    ):\n",
    "    test_tracks = []\n",
    "    for fpath in f_list:\n",
    "        fpath = Path(fpath)\n",
    "        parsed_keys = parse.parse(trk_template, fpath.name)\n",
    "        temp = pd.read_csv(fpath, sep=\"\\s+\", header=None)\n",
    "        #print(temp)\n",
    "        temp.columns = [\"x\", \"y\", \"I\", \"t\", \"state\"]\n",
    "        temp[\"cell\"] = int(parsed_keys[\"cell\"]) # type: ignore\n",
    "        if \"spot\" in parsed_keys.named.keys():\n",
    "            temp[\"ID\"] = int(parsed_keys[\"spot\"]) # type: ignore\n",
    "        else:\n",
    "            temp[\"ID\"] = 3\n",
    "        temp[\"UUID\"] = temp[\"cell\"].astype(str) + \"_\" + temp[\"ID\"].astype(str)\n",
    "        test_tracks.append(temp)\n",
    "    full_df = pd.concat(test_tracks)\n",
    "    full_df[\"ID\"] = full_df[\"ID\"].astype(int)\n",
    "    return full_df\n",
    "\n",
    "def fwf_writer(fname, df):\n",
    "    # TODO figure out how to automatically create format spec\n",
    "    with open(fname, \"w\") as f:\n",
    "        if isinstance(df, pd.DataFrame):\n",
    "            for i, data in df.iterrows():\n",
    "                f.write(\"\".join([\"{:>11.3f}    \".format(num) for num in data])+\"\\n\")\n",
    "        else:\n",
    "            for data in df:\n",
    "                f.write(\"\".join([\"{:>11.3f}    \".format(num) for num in data])+\"\\n\")\n",
    "\n",
    "def new_qc(g_df, gpath, ch):\n",
    "    g_df_qc = []\n",
    "    for i, (UUID, group) in enumerate(g_df.groupby(\"UUID\")):\n",
    "        trk_df = group.drop_duplicates(subset=\"t\", keep=\"first\")\n",
    "        outliers = trk_df[\"I\"] > (4096 * 2)\n",
    "        trk_df.loc[outliers, \"I\"] = pd.NA\n",
    "        time_range = pd.RangeIndex(start=trk_df['t'].min(), stop=trk_df['t'].max() + 1)\n",
    "        df_continuous = trk_df.set_index('t').reindex(time_range).reset_index()\n",
    "        df_continuous.rename(columns={'index': 't'}, inplace=True)\n",
    "        df_continuous['I'] = df_continuous['I'].fillna(np.nanpercentile(df_continuous[\"I\"], 10))\n",
    "        df_continuous['x'] = df_continuous['x'].interpolate(method='linear')\n",
    "        df_continuous['y'] = df_continuous['y'].interpolate(method='linear')\n",
    "        trk_df = df_continuous.copy()\n",
    "        if len(trk_df[\"t\"]) != trk_df[\"t\"].max() - trk_df[\"t\"].min()+1:\n",
    "            print(UUID)\n",
    "        trk_df[\"UUID\"] = UUID\n",
    "        trk_df.loc[:,\"state\"] = 0\n",
    "        trk_df.drop(index=0, inplace=True)\n",
    "        fwf_writer(gpath.joinpath(\"{:03d}{}_DualColor_segChG.trk\".format(i, ch)), trk_df[[\"x\", \"y\", \"I\", \"t\", \"state\"]])\n",
    "        g_df_qc.append(trk_df)\n",
    "    g_df_qc = pd.concat(g_df_qc)\n",
    "    return g_df_qc\n",
    "\n",
    "def write_matched(g_df_qc, r_df_qc, cpath, spath, dist_threshold=5, min_lifetime=20, n=500, ): \n",
    "    \"\"\"\n",
    "    g_df_qc: preprocessed dataframe containing all green tracks\n",
    "    r_df_qc: preprocessed dataframe containing all  red  tracks\n",
    "    cpath: Coupled tracks output\n",
    "    spath: shuffled tracks output\n",
    "    dist_threshold: distance threshold for collision\n",
    "    min_lifetime: minimum collision time to be considered coupled\n",
    "    n = number of permutations\n",
    "    \"\"\"\n",
    "    matched = naive_match_collisions(g_df_qc, r_df_qc, threshold=dist_threshold, min_lifetime=min_lifetime)\n",
    "    print(matched, \"\\n\",len(matched))\n",
    "    print(\"matching\")\n",
    "    for i, (gid, rid) in enumerate(matched):\n",
    "        gtrk = g_df_qc[g_df_qc[\"UUID\"] == gid]\n",
    "        rtrk = r_df_qc[r_df_qc[\"UUID\"] == rid]\n",
    "        min_t = max(gtrk[\"t\"].min(), rtrk[\"t\"].min())\n",
    "        max_t = min(gtrk[\"t\"].max(), rtrk[\"t\"].max())\n",
    "        gtrk = gtrk[(gtrk[\"t\"] < max_t) * (gtrk[\"t\"] > min_t)]\n",
    "        rtrk = rtrk[(rtrk[\"t\"] < max_t) * (rtrk[\"t\"] > min_t)]\n",
    "        fwf_writer(cpath.joinpath(\"{:03d}G_DualColor_segChG.trk\".format(i)), gtrk[[\"x\", \"y\", \"I\", \"t\", \"state\"]])    \n",
    "        fwf_writer(cpath.joinpath(\"{:03d}R_DualColor_segChG.trk\".format(i)), rtrk[[\"x\", \"y\", \"I\", \"t\", \"state\"]])\n",
    "\n",
    "    idx = np.mod(np.arange(n), len(matched))\n",
    "    r_idx = np.random.permutation(n)\n",
    "    r_idx = np.mod(r_idx, len(matched))\n",
    "    print(\"shuffling\")\n",
    "    for j, i in enumerate(r_idx):\n",
    "        gid = matched[idx[j]][0]\n",
    "        rid = matched[i][1]\n",
    "        gtrk = g_df_qc[g_df_qc[\"UUID\"] == gid][[\"x\", \"y\", \"I\", \"t\", \"state\"]].copy()\n",
    "        rtrk = r_df_qc[r_df_qc[\"UUID\"] == rid][[\"x\", \"y\", \"I\", \"t\", \"state\"]].copy()\n",
    "        min_t = max(gtrk[\"t\"].min(), rtrk[\"t\"].min())\n",
    "        max_t = min(gtrk[\"t\"].max(), rtrk[\"t\"].max())\n",
    "\n",
    "        gtrk = gtrk[(gtrk[\"t\"] < max_t) * (gtrk[\"t\"] > min_t)]\n",
    "        rtrk = rtrk[(rtrk[\"t\"] < max_t) * (rtrk[\"t\"] > min_t)]\n",
    "        gtrk[\"t\"] = gtrk[\"t\"] - gtrk[\"t\"].min()\n",
    "        rtrk[\"t\"] = rtrk[\"t\"] - rtrk[\"t\"].min()\n",
    "        fwf_writer(spath.joinpath(\"{:03d}G_DualColor_segChG.trk\".format(j)), gtrk[[\"x\", \"y\", \"I\", \"t\", \"state\"]])    \n",
    "        fwf_writer(spath.joinpath(\"{:03d}R_DualColor_segChG.trk\".format(j)), rtrk[[\"x\", \"y\", \"I\", \"t\", \"state\"]]) \n",
    "\n",
    "def preprocess_tracks(path_list, out_path, out_path2=None):\n",
    "    out_path = Path(out_path)\n",
    "    check_dir(out_path, create_if_not=True)\n",
    "\n",
    "    trk_list = []\n",
    "    indices = []\n",
    "    for i, search_path in enumerate(path_list):\n",
    "        temp_list = list(Path(search_path).joinpath(\"sc_idl\").glob(\"*\\\\*.trk\"))\n",
    "        trk_list.extend(temp_list)\n",
    "        indices.extend([i+1 for j in range(len(temp_list))])\n",
    "    if len(trk_list) == 0:\n",
    "        raise RuntimeError(\"No tracks found\")\n",
    "    for i, trk_path in enumerate(trk_list):\n",
    "        # print(trk_path)\n",
    "        i = indices[i]\n",
    "        new_name = trk_path.name\n",
    "        new_name = str(i) + new_name\n",
    "        sh.copy2(trk_path, out_path.joinpath(new_name))\n",
    "    gpath = out_path.joinpath(\"gene\")\n",
    "    rpath = out_path.joinpath(\"enhancer\")\n",
    "    cpath = out_path.joinpath(\"coupled\")\n",
    "    spath = out_path.joinpath(\"shuffled\")\n",
    "    for i in [gpath, rpath, cpath, spath]:\n",
    "        check_dir(i, create_if_not=True)\n",
    "        sh.copy2(r\"fcsApp.sav\", i)\n",
    "\n",
    "    g_list = list(out_path.glob(\"*G_*ot*_t*.trk\"))\n",
    "    r_list = list(out_path.glob(\"*R_*ot*_t*.trk\"))\n",
    "    if len(g_list) == 0 and len(r_list) == 0:\n",
    "        raise RuntimeError(\"Naming convention does not match\")\n",
    "    \n",
    "    print(\"reading\")\n",
    "    g_df = batch_read_tracks(g_list, g_template)\n",
    "    r_df = batch_read_tracks(r_list, r_template)\n",
    "\n",
    "    print(\"qc\")\n",
    "    g_df_qc = new_qc(g_df, gpath, \"G\")\n",
    "    r_df_qc = new_qc(r_df, rpath, \"R\")\n",
    "    print(\"Found matched pairs:\")\n",
    "    write_matched(g_df_qc, r_df_qc, cpath, spath)\n",
    "    \n",
    "    if out_path2 is not None:\n",
    "        out_path2 = Path(out_path2)\n",
    "        check_dir(out_path2, create_if_not=True)\n",
    "        print(\"copying to local...\")\n",
    "        sh.copytree(out_path, out_path2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. This does some tricks to automatically get filenames under a certain convention: if the folder names match the image names without the stem, then this code will work, otherwise, definte fpath_list by hand to contain all the folders that make up a single replicate/condition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\\\shares2.dkisilon2.niddk.nih.gov\\DKMIROSHNIKOVALAB\\Lab Notebooks\\Ike\\009-0\\009-0_Control_0001-MaxIP_XY1\n",
      "\\\\shares2.dkisilon2.niddk.nih.gov\\DKMIROSHNIKOVALAB\\Lab Notebooks\\Ike\\009-0\\009-0_Control_0001-MaxIP_XY2\n",
      "\\\\shares2.dkisilon2.niddk.nih.gov\\DKMIROSHNIKOVALAB\\Lab Notebooks\\Ike\\009-0\\009-0_Control_0001-MaxIP_XY3\n",
      "\\\\shares2.dkisilon2.niddk.nih.gov\\DKMIROSHNIKOVALAB\\Lab Notebooks\\Ike\\009-0\\009-0_Control_0001-MaxIP_XY4\n"
     ]
    }
   ],
   "source": [
    "# use to find replicates/fields of experiments\n",
    "exp_path = Path(\n",
    "\"\\\\\\\\shares2.dkisilon2.niddk.nih.gov\\\\DKMIROSHNIKOVALAB\\\\Lab Notebooks\\\\Ike\"\n",
    ")\n",
    "\n",
    "exp_list = [\"009-0\"]\n",
    "check_dir(exp_path, raise_if_false=True)\n",
    "fpath_list = [sorted(exp_path.joinpath(exp_code).glob(\"*.ome.tif\")) for exp_code in exp_list]\n",
    "fpath_list = [x for p_list in fpath_list for x in p_list]\n",
    "fpath_list = [fpath.parent.joinpath(Path(fpath.stem).stem) for fpath in fpath_list]\n",
    "\n",
    "for fpath in fpath_list:\n",
    "    print(fpath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Run using the defined fpath list, an output folder, and an optional second output folder (one for storage and one to run locally because IDL does not play nicely with servers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\\\shares2.dkisilon2.niddk.nih.gov\\DKMIROSHNIKOVALAB\\Lab Notebooks\\Ike\\009-0\\009-0_Control_0001-MaxIP_XY1\n",
      "\\\\shares2.dkisilon2.niddk.nih.gov\\DKMIROSHNIKOVALAB\\Lab Notebooks\\Ike\\009-0\\009-0_Control_0001-MaxIP_XY2\n",
      "\\\\shares2.dkisilon2.niddk.nih.gov\\DKMIROSHNIKOVALAB\\Lab Notebooks\\Ike\\009-0\\009-0_Control_0001-MaxIP_XY3\n",
      "\\\\shares2.dkisilon2.niddk.nih.gov\\DKMIROSHNIKOVALAB\\Lab Notebooks\\Ike\\009-0\\009-0_Control_0001-MaxIP_XY4\n",
      "reading\n",
      "qc\n",
      "[('1001_0', '1001_0'), ('1012_0', '1012_0'), ('1018_1', '1018_0'), ('1019_2', '1019_1'), ('1021_1', '1021_0'), ('2002_0', '2002_0'), ('2011_0', '2011_0'), ('2017_0', '2017_1'), ('2024_2', '2024_0'), ('2025_0', '2025_1'), ('2025_2', '2025_2'), ('2026_1', '2026_0'), ('2029_1', '2029_0'), ('2030_1', '2030_0'), ('2041_0', '2041_2'), ('2042_1', '2042_0'), ('2043_2', '2043_1'), ('2044_0', '2044_0'), ('2045_1', '2045_2'), ('3007_0', '3007_0'), ('3009_1', '3009_0'), ('3012_1', '3012_0'), ('3016_0', '3016_0'), ('3017_2', '3017_0'), ('3025_1', '3025_0'), ('3030_0', '3030_2'), ('3032_2', '3032_2'), ('4001_1', '4001_0'), ('4006_0', '4006_0'), ('4009_1', '4009_0'), ('4018_0', '4018_0'), ('4035_2', '4035_2')] \n",
      " 32\n",
      "matching\n",
      "shuffling\n"
     ]
    }
   ],
   "source": [
    "preprocess_tracks(fpath_list, r\"c:\\Users\\Imageanalysis\\Desktop\\Ike\\test_folder\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hitips2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
