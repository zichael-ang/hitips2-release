{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After IDL tracking, this notebook collects track files, does preprocessing (removing outliers, filling in missing values, cropping times)\n",
    "\n",
    "1. Run this block to set up \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ht2.utils import *\n",
    "from ht2.quant import *\n",
    "from ht2.qc import *\n",
    "from ht2.io_handler import *\n",
    "import shutil as sh\n",
    "import pandas as pd\n",
    "\n",
    "g_template = \"{cell}G_{reg}ot{spot}_t{len}.{extension}\"\n",
    "r_template = \"{cell}R_{reg}ot{spot}_t{len}.{extension}\"\n",
    "\n",
    "\n",
    "# TODO Keep images and tracks together, refit spots using track and image data, compute noise priors, \n",
    "\n",
    "\n",
    "def batch_read_tracks(f_list, \n",
    "    trk_template\n",
    "    ):\n",
    "    test_tracks = []\n",
    "    for fpath in f_list:\n",
    "        fpath = Path(fpath)\n",
    "        parsed_keys = parse.parse(trk_template, fpath.name)\n",
    "        temp = pd.read_csv(fpath, sep=\"\\s+\", header=None)\n",
    "        #print(temp)\n",
    "        temp.columns = [\"x\", \"y\", \"I\", \"t\", \"state\"]\n",
    "        temp[\"cell\"] = int(parsed_keys[\"cell\"]) # type: ignore\n",
    "        if \"spot\" in parsed_keys.named.keys():\n",
    "            temp[\"ID\"] = int(parsed_keys[\"spot\"]) # type: ignore\n",
    "        else:\n",
    "            temp[\"ID\"] = 3\n",
    "        temp[\"UUID\"] = temp[\"cell\"].astype(str) + \"_\" + temp[\"ID\"].astype(str)\n",
    "        test_tracks.append(temp)\n",
    "    full_df = pd.concat(test_tracks)\n",
    "    full_df[\"ID\"] = full_df[\"ID\"].astype(int)\n",
    "    return full_df\n",
    "\n",
    "def fwf_writer(fname, df):\n",
    "    # TODO figure out how to automatically create format spec\n",
    "    with open(fname, \"w\") as f:\n",
    "        if isinstance(df, pd.DataFrame):\n",
    "            for i, data in df.iterrows():\n",
    "                f.write(\"\".join([\"{:>11.3f}    \".format(num) for num in data])+\"\\n\")\n",
    "        else:\n",
    "            for data in df:\n",
    "                f.write(\"\".join([\"{:>11.3f}    \".format(num) for num in data])+\"\\n\")\n",
    "\n",
    "\n",
    "def new_qc(g_df, gpath, ch, normalize=True):\n",
    "    g_df_qc = []\n",
    "    for i, (UUID, group) in enumerate(g_df.groupby(\"UUID\")):\n",
    "        trk_df = group.drop_duplicates(subset=\"t\", keep=\"first\")\n",
    "        outliers = trk_df[\"I\"] > (4096 * 3)\n",
    "        trk_df.loc[outliers, \"I\"] = pd.NA\n",
    "        time_range = pd.RangeIndex(start=trk_df['t'].min(), stop=trk_df['t'].max() + 1)\n",
    "        df_continuous = trk_df.set_index('t').reindex(time_range).reset_index()\n",
    "        df_continuous.rename(columns={'index': 't'}, inplace=True)\n",
    "        df_continuous['I'] = df_continuous['I'].fillna(np.nanpercentile(df_continuous[\"I\"], 10))\n",
    "        df_continuous['x'] = df_continuous['x'].interpolate(method='linear')\n",
    "        df_continuous['y'] = df_continuous['y'].interpolate(method='linear')\n",
    "        trk_df = df_continuous.copy()\n",
    "        if len(trk_df[\"t\"]) != trk_df[\"t\"].max() - trk_df[\"t\"].min()+1:\n",
    "            print(UUID)\n",
    "        trk_df[\"UUID\"] = UUID\n",
    "        trk_df.loc[:,\"state\"] = 0\n",
    "        trk_df.drop(index=0, inplace=True)\n",
    "        if normalize:\n",
    "            trk_df['I'] = robust_z_score(trk_df[\"I\"])\n",
    "\n",
    "        g_df_qc.append(trk_df)\n",
    "    g_df_qc = pd.concat(g_df_qc)\n",
    "    if normalize:\n",
    "        g_df_qc[\"I\"] = ((1000 * (g_df_qc[\"I\"] - np.nanmin(g_df_qc[\"I\"])))).astype(int)\n",
    "    for i, (UUID, trk_df) in enumerate(g_df.groupby(\"UUID\")):\n",
    "        fwf_writer(gpath.joinpath(\"{:03d}{}_DualColor_segChG.trk\".format(i, ch)), trk_df[[\"x\", \"y\", \"I\", \"t\", \"state\"]])\n",
    "    return g_df_qc\n",
    "\n",
    "def write_matched(g_df_qc, r_df_qc, cpath, spath, dist_threshold=5, min_lifetime=20, n=500, ): \n",
    "    \"\"\"\n",
    "    g_df_qc: preprocessed dataframe containing all green tracks\n",
    "    r_df_qc: preprocessed dataframe containing all  red  tracks\n",
    "    cpath: Coupled tracks output\n",
    "    spath: shuffled tracks output\n",
    "    dist_threshold: distance threshold for collision\n",
    "    min_lifetime: minimum collision time to be considered coupled\n",
    "    n = number of permutations\n",
    "    \"\"\"\n",
    "    matched = naive_match_collisions(g_df_qc, r_df_qc, threshold=dist_threshold, min_lifetime=min_lifetime)\n",
    "    print(matched, \"\\n\",len(matched))\n",
    "    print(\"matching\")\n",
    "    for i, (gid, rid) in enumerate(matched):\n",
    "        gtrk = g_df_qc[g_df_qc[\"UUID\"] == gid]\n",
    "        rtrk = r_df_qc[r_df_qc[\"UUID\"] == rid]\n",
    "        min_t = max(gtrk[\"t\"].min(), rtrk[\"t\"].min())\n",
    "        max_t = min(gtrk[\"t\"].max(), rtrk[\"t\"].max())\n",
    "        gtrk = gtrk[(gtrk[\"t\"] < max_t) * (gtrk[\"t\"] > min_t)]\n",
    "        rtrk = rtrk[(rtrk[\"t\"] < max_t) * (rtrk[\"t\"] > min_t)]\n",
    "        fwf_writer(cpath.joinpath(\"{:03d}G_DualColor_segChG.trk\".format(i)), gtrk[[\"x\", \"y\", \"I\", \"t\", \"state\"]])    \n",
    "        fwf_writer(cpath.joinpath(\"{:03d}R_DualColor_segChG.trk\".format(i)), rtrk[[\"x\", \"y\", \"I\", \"t\", \"state\"]])\n",
    "\n",
    "    idx = np.mod(np.arange(n), len(matched))\n",
    "    r_idx = np.random.permutation(n)\n",
    "    r_idx = np.mod(r_idx, len(matched))\n",
    "    print(\"shuffling\")\n",
    "    for j, i in enumerate(r_idx):\n",
    "        gid = matched[idx[j]][0]\n",
    "        rid = matched[i][1]\n",
    "        gtrk = g_df_qc[g_df_qc[\"UUID\"] == gid][[\"x\", \"y\", \"I\", \"t\", \"state\"]].copy()\n",
    "        rtrk = r_df_qc[r_df_qc[\"UUID\"] == rid][[\"x\", \"y\", \"I\", \"t\", \"state\"]].copy()\n",
    "        min_t = max(gtrk[\"t\"].min(), rtrk[\"t\"].min())\n",
    "        max_t = min(gtrk[\"t\"].max(), rtrk[\"t\"].max())\n",
    "\n",
    "        gtrk = gtrk[(gtrk[\"t\"] < max_t) * (gtrk[\"t\"] > min_t)]\n",
    "        rtrk = rtrk[(rtrk[\"t\"] < max_t) * (rtrk[\"t\"] > min_t)]\n",
    "        gtrk[\"t\"] = gtrk[\"t\"] - gtrk[\"t\"].min()\n",
    "        rtrk[\"t\"] = rtrk[\"t\"] - rtrk[\"t\"].min()\n",
    "        fwf_writer(spath.joinpath(\"{:03d}G_DualColor_segChG.trk\".format(j)), gtrk[[\"x\", \"y\", \"I\", \"t\", \"state\"]])    \n",
    "        fwf_writer(spath.joinpath(\"{:03d}R_DualColor_segChG.trk\".format(j)), rtrk[[\"x\", \"y\", \"I\", \"t\", \"state\"]]) \n",
    "\n",
    "def preprocess_tracks(path_list, out_path, out_path2=None, normalize=[True, True], save_images=True):\n",
    "    out_path = Path(out_path)\n",
    "    check_dir(out_path, create_if_not=True)\n",
    "    gpath = out_path.joinpath(\"gene\")\n",
    "    rpath = out_path.joinpath(\"enhancer\")\n",
    "    cpath = out_path.joinpath(\"coupled\")\n",
    "    spath = out_path.joinpath(\"shuffled\")\n",
    "    for i in [gpath, rpath, cpath, spath]:\n",
    "        check_dir(i, create_if_not=True)\n",
    "        sh.copy2(r\"fcsApp.sav\", i)\n",
    "\n",
    "    trk_list = []\n",
    "    indices = []\n",
    "    for i, search_path in enumerate(path_list):\n",
    "        temp_list = list(Path(search_path).joinpath(\"sc_idl\").glob(\"*\\\\*.trk\"))\n",
    "        trk_list.extend(temp_list)\n",
    "        indices.extend([i+1 for j in range(len(temp_list))])\n",
    "    if len(trk_list) == 0:\n",
    "        raise RuntimeError(\"No tracks found\")\n",
    "    for i, trk_path in enumerate(trk_list):\n",
    "        # print(trk_path)\n",
    "        i = indices[i]\n",
    "        new_name = trk_path.name\n",
    "        new_name = str(i) + new_name\n",
    "        sh.copy2(trk_path.parent.joinpath(trk_path.name.replace(\".trk\", \".tif\")), out_path.joinpath(new_name.replace(\".trk\", \".tif\")))\n",
    "        sh.copy2(trk_path, out_path.joinpath(new_name))\n",
    "\n",
    "    g_list = list(out_path.glob(\"*G_*ot*_t*.trk\"))\n",
    "    r_list = list(out_path.glob(\"*R_*ot*_t*.trk\"))\n",
    "    if len(g_list) == 0 and len(r_list) == 0:\n",
    "        raise RuntimeError(\"Naming convention does not match\")\n",
    "\n",
    "    print(\"reading\")\n",
    "    g_df = batch_read_tracks(g_list, g_template)\n",
    "    r_df = batch_read_tracks(r_list, r_template)\n",
    "    print(\"qc\")\n",
    "    g_df_qc = new_qc(g_df, gpath, \"G\", normalize=True)\n",
    "    r_df_qc = new_qc(r_df, rpath, \"R\", normalize=True)\n",
    "    if save_images:\n",
    "        for i, g_trk_path in enumerate(g_list):\n",
    "            im_path = g_trk_path.parent.joinpath(g_trk_path.name.replace(\".trk\", \".tif\"))\n",
    "            sh.copy2(im_path, gpath.joinpath(\"{:03d}G_image.tif\".format(i)))\n",
    "        for i, r_trk_path in enumerate(r_list):\n",
    "            im_path = r_trk_path.parent.joinpath(r_trk_path.name.replace(\".trk\", \".tif\"))\n",
    "            sh.copy2(im_path, rpath.joinpath(\"{:03d}R_image.tif\".format(i)))\n",
    "    print(\"Found matched pairs:\")\n",
    "    write_matched(g_df_qc, r_df_qc, cpath, spath)\n",
    "    plt.hist(g_df_qc[\"I\"], 1000)\n",
    "    plt.show()\n",
    "    plt.hist(r_df_qc[\"I\"], 1000)\n",
    "    plt.show()\n",
    "    \n",
    "    if out_path2 is not None:\n",
    "        out_path2 = Path(out_path2)\n",
    "        check_dir(out_path2, create_if_not=True)\n",
    "        print(\"copying to local...\")\n",
    "        sh.copytree(out_path, out_path2)\n",
    "    return g_df_qc, r_df_qc\n",
    "\n",
    "def SG_qc(g_df, gpath, ch, normalize=True):\n",
    "    ch_map = {\"G\":\"gene\", \"R\":\"enhancer\"}\n",
    "    g_df_qc = []\n",
    "    for i, (UUID, group) in enumerate(g_df.groupby(\"UUID\")):\n",
    "        trk_df = group.drop_duplicates(subset=\"t\", keep=\"first\")\n",
    "        outliers = trk_df[\"I\"] > (4096 * 3)\n",
    "        trk_df.loc[outliers, \"I\"] = pd.NA\n",
    "        time_range = pd.RangeIndex(start=trk_df['t'].min(), stop=trk_df['t'].max() + 1)\n",
    "        df_continuous = trk_df.set_index('t').reindex(time_range).reset_index()\n",
    "        df_continuous.rename(columns={'index': 't'}, inplace=True)\n",
    "        df_continuous['I'] = df_continuous['I'].fillna(np.nanpercentile(df_continuous[\"I\"], 10))\n",
    "        df_continuous['x'] = df_continuous['x'].interpolate(method='linear')\n",
    "        df_continuous['y'] = df_continuous['y'].interpolate(method='linear')\n",
    "        trk_df = df_continuous.copy()\n",
    "        if len(trk_df[\"t\"]) != trk_df[\"t\"].max() - trk_df[\"t\"].min()+1:\n",
    "            print(UUID)\n",
    "        trk_df[\"UUID\"] = UUID\n",
    "        trk_df.loc[:,\"state\"] = 0\n",
    "        trk_df.drop(trk_df[trk_df[\"t\"] == 0].index, inplace=True)\n",
    "        if normalize:\n",
    "            trk_df['I'] = robust_z_score(trk_df[\"I\"])\n",
    "\n",
    "        g_df_qc.append(trk_df)\n",
    "    g_df_qc = pd.concat(g_df_qc)\n",
    "    if normalize:\n",
    "        g_df_qc[\"I\"] = ((1000 * (g_df_qc[\"I\"] - np.nanmin(g_df_qc[\"I\"])))).astype(int)\n",
    "    for i, (UUID, trk_df) in enumerate(g_df.groupby(\"UUID\")):\n",
    "        fwf_writer(gpath.joinpath(\"{:03d}_{}.trk\".format(i, ch_map[ch])), trk_df[[\"x\", \"y\", \"I\", \"t\", \"state\"]])\n",
    "    return g_df_qc\n",
    "\n",
    "def SG_preprocess_tracks(path_list, out_path, out_path2=None, normalize=[True, True], save_images=True):\n",
    "    out_path = Path(out_path)\n",
    "    check_dir(out_path, create_if_not=True)\n",
    "    gpath = out_path.joinpath(\"gene\")\n",
    "    rpath = out_path.joinpath(\"enhancer\")\n",
    "    cpath = out_path.joinpath(\"coupled\")\n",
    "    gim_path = out_path.joinpath(\"gene_im\")\n",
    "    rim_path = out_path.joinpath(\"enhancer_im\")\n",
    "    cim_path = out_path.joinpath(\"coupled_im\")\n",
    "    spath = out_path.joinpath(\"shuffled\")\n",
    "    for i in [gpath, rpath, cpath, spath, gim_path, rim_path, cim_path]:\n",
    "        check_dir(i, create_if_not=True)\n",
    "\n",
    "    trk_list = []\n",
    "    indices = []\n",
    "    for i, search_path in enumerate(path_list):\n",
    "        temp_list = list(Path(search_path).joinpath(\"sc_idl\").glob(\"*\\\\*.trk\"))\n",
    "        trk_list.extend(temp_list)\n",
    "        indices.extend([i+1 for j in range(len(temp_list))])\n",
    "    if len(trk_list) == 0:\n",
    "        raise RuntimeError(\"No tracks found\")\n",
    "    for i, trk_path in enumerate(trk_list):\n",
    "        # print(trk_path)\n",
    "        i = indices[i]\n",
    "        new_name = trk_path.name\n",
    "        new_name = str(i) + new_name\n",
    "        if save_images:\n",
    "            sh.copy2(trk_path.parent.joinpath(trk_path.name.replace(\".trk\", \".tif\")), out_path.joinpath(new_name.replace(\".trk\", \".tif\")))\n",
    "        sh.copy2(trk_path, out_path.joinpath(new_name))\n",
    "\n",
    "    g_list = list(out_path.glob(\"*G_*ot*_t*.trk\"))\n",
    "    r_list = list(out_path.glob(\"*R_*ot*_t*.trk\"))\n",
    "    if len(g_list) == 0 and len(r_list) == 0:\n",
    "        raise RuntimeError(\"Naming convention does not match\")\n",
    "\n",
    "    print(\"reading\")\n",
    "    g_df = batch_read_tracks(g_list, g_template)\n",
    "    r_df = batch_read_tracks(r_list, r_template)\n",
    "    print(\"qc\")\n",
    "    g_df_qc = SG_qc(g_df, gpath, \"G\", normalize=True)\n",
    "    r_df_qc = SG_qc(r_df, rpath, \"R\", normalize=True)\n",
    "    if save_images:\n",
    "        for i, g_trk_path in enumerate(g_list):\n",
    "            im_path = g_trk_path.parent.joinpath(g_trk_path.name.replace(\".trk\", \".tif\"))\n",
    "            sh.copy2(im_path, gim_path.joinpath(\"{:03d}_G_image.tif\".format(i)))\n",
    "        for i, r_trk_path in enumerate(r_list):\n",
    "            im_path = r_trk_path.parent.joinpath(r_trk_path.name.replace(\".trk\", \".tif\"))\n",
    "            sh.copy2(im_path, rim_path.joinpath(\"{:03d}_R_image.tif\".format(i)))\n",
    "    print(\"Found matched pairs:\")\n",
    "    write_matched(g_df_qc, r_df_qc, cpath, spath, n=80)\n",
    "    plt.hist(g_df_qc[\"I\"], 1000)\n",
    "    plt.show()\n",
    "    plt.hist(r_df_qc[\"I\"], 1000)\n",
    "    plt.show()\n",
    "    \n",
    "    if out_path2 is not None:\n",
    "        out_path2 = Path(out_path2)\n",
    "        check_dir(out_path2, create_if_not=True)\n",
    "        print(\"copying to local...\")\n",
    "        sh.copytree(out_path, out_path2)\n",
    "    return g_df_qc, r_df_qc\n",
    "\n",
    "def robust_z_score(y):\n",
    "    med = np.nanmedian(y)\n",
    "    z = y - med\n",
    "    z = 0.6745 * z / np.nanmedian(np.abs(z))\n",
    "    return z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. This does some tricks to automatically get filenames under a certain convention: if the folder names match the image names without the stem, then this code will work, otherwise, definte fpath_list by hand to contain all the folders that make up a single replicate/condition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\" in \"food\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def organize_fpaths(root_dir, cond_list, key_list, im_suffix=\".ome.tif\"):\n",
    "    if isinstance(im_suffix, str):\n",
    "        im_suffix_list = [im_suffix for i in range(len(cond_list))]\n",
    "    cond_path_lists = []\n",
    "    for keys_, cond_, im_suff in zip(key_list, cond_list, im_suffix_list):\n",
    "        if isinstance(cond_, str):\n",
    "            cond = [cond_]\n",
    "        else:\n",
    "            cond = cond_\n",
    "        if isinstance(keys_, str):\n",
    "            keys = [keys_]\n",
    "        else:\n",
    "            keys = keys_\n",
    "        im_list = [sorted(root_dir.joinpath(exp_code).glob(\"*{}\".format(im_suff))) for exp_code in cond]\n",
    "        for key in keys:\n",
    "            match_list = [x for p_list in im_list for x in p_list if key in x]\n",
    "            folder_list = [fpath.parent.joinpath(Path(fpath.stem).stem) for fpath in match_list]\n",
    "            cond_path_lists.append(folder_list)\n",
    "            print(folder_list)\n",
    "    return cond_path_lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_path = Path(\n",
    "\"\\\\\\\\shares2.dkisilon2.niddk.nih.gov\\\\DKMIROSHNIKOVALAB\\\\Lab Notebooks\\\\Ike\"\n",
    ")\n",
    "organize_fpaths(exp_path, [\"005-1\", \"004-4\", \"001-1\", \"003-4\", \"009-0\", \"Retro\\\\56\", \"Retro\\\\47_49\"], \n",
    "                          [\"\", \"\", [\"MaxIP_fn\", \"MaxIP_lam\"], [\"soft_fn\", \"soft_lam\", \"stiff_fn\", \"stiff_lam\",], \"\", \"\", \"\",])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[WindowsPath('//shares2.dkisilon2.niddk.nih.gov/DKMIROSHNIKOVALAB/Lab Notebooks/Ike/005-1/006-1_FN_STRETCH_CTRL_MaxIP_A1_t577.ome.tif'), WindowsPath('//shares2.dkisilon2.niddk.nih.gov/DKMIROSHNIKOVALAB/Lab Notebooks/Ike/005-1/006-1_FN_STRETCH_CTRL_MaxIP_A2_t577.ome.tif')], [WindowsPath('//shares2.dkisilon2.niddk.nih.gov/DKMIROSHNIKOVALAB/Lab Notebooks/Ike/004-4/004-4_FN_STRETCH_2_MaxIP_XY1_t430.ome.tif'), WindowsPath('//shares2.dkisilon2.niddk.nih.gov/DKMIROSHNIKOVALAB/Lab Notebooks/Ike/004-4/004-4_FN_STRETCH_2_MaxIP_XY2_t577.ome.tif')]]\n",
      "[WindowsPath('//shares2.dkisilon2.niddk.nih.gov/DKMIROSHNIKOVALAB/Lab Notebooks/Ike/005-1/006-1_FN_STRETCH_CTRL_MaxIP_A1_t577.ome.tif'), WindowsPath('//shares2.dkisilon2.niddk.nih.gov/DKMIROSHNIKOVALAB/Lab Notebooks/Ike/005-1/006-1_FN_STRETCH_CTRL_MaxIP_A2_t577.ome.tif'), WindowsPath('//shares2.dkisilon2.niddk.nih.gov/DKMIROSHNIKOVALAB/Lab Notebooks/Ike/004-4/004-4_FN_STRETCH_2_MaxIP_XY1_t430.ome.tif'), WindowsPath('//shares2.dkisilon2.niddk.nih.gov/DKMIROSHNIKOVALAB/Lab Notebooks/Ike/004-4/004-4_FN_STRETCH_2_MaxIP_XY2_t577.ome.tif')]\n",
      "[WindowsPath('//shares2.dkisilon2.niddk.nih.gov/DKMIROSHNIKOVALAB/Lab Notebooks/Ike/005-1/006-1_FN_STRETCH_CTRL_MaxIP_A1_t577'), WindowsPath('//shares2.dkisilon2.niddk.nih.gov/DKMIROSHNIKOVALAB/Lab Notebooks/Ike/005-1/006-1_FN_STRETCH_CTRL_MaxIP_A2_t577'), WindowsPath('//shares2.dkisilon2.niddk.nih.gov/DKMIROSHNIKOVALAB/Lab Notebooks/Ike/004-4/004-4_FN_STRETCH_2_MaxIP_XY1_t430'), WindowsPath('//shares2.dkisilon2.niddk.nih.gov/DKMIROSHNIKOVALAB/Lab Notebooks/Ike/004-4/004-4_FN_STRETCH_2_MaxIP_XY2_t577')]\n",
      "\\\\shares2.dkisilon2.niddk.nih.gov\\DKMIROSHNIKOVALAB\\Lab Notebooks\\Ike\\005-1\\006-1_FN_STRETCH_CTRL_MaxIP_A1_t577\n",
      "\\\\shares2.dkisilon2.niddk.nih.gov\\DKMIROSHNIKOVALAB\\Lab Notebooks\\Ike\\005-1\\006-1_FN_STRETCH_CTRL_MaxIP_A2_t577\n",
      "\\\\shares2.dkisilon2.niddk.nih.gov\\DKMIROSHNIKOVALAB\\Lab Notebooks\\Ike\\004-4\\004-4_FN_STRETCH_2_MaxIP_XY1_t430\n",
      "\\\\shares2.dkisilon2.niddk.nih.gov\\DKMIROSHNIKOVALAB\\Lab Notebooks\\Ike\\004-4\\004-4_FN_STRETCH_2_MaxIP_XY2_t577\n"
     ]
    }
   ],
   "source": [
    "# use to find replicates/fields of experiments\n",
    "exp_path = Path(\n",
    "\"\\\\\\\\shares2.dkisilon2.niddk.nih.gov\\\\DKMIROSHNIKOVALAB\\\\Lab Notebooks\\\\Ike\"\n",
    ")\n",
    "# for exp_list in [\"\"]\n",
    "exp_list = [\"005-1\", \"004-4\"]\n",
    "check_dir(exp_path, raise_if_false=True)\n",
    "fpath_list = [sorted(exp_path.joinpath(exp_code).glob(\"*.ome.tif\")) for exp_code in exp_list]\n",
    "print(fpath_list)\n",
    "fpath_list = [x for p_list in fpath_list for x in p_list]\n",
    "print(fpath_list)\n",
    "fpath_list = [fpath.parent.joinpath(Path(fpath.stem).stem) for fpath in fpath_list]\n",
    "print(fpath_list)\n",
    "for fpath in fpath_list:\n",
    "    print(fpath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Run using the defined fpath list, an output folder, and an optional second output folder (one for storage and one to run locally because IDL does not play nicely with servers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pick root path\n",
    "# for each condition, specify folder(s) and key(s)\n",
    "\n",
    "root_path = Path(\n",
    "\"\\\\\\\\shares2.dkisilon2.niddk.nih.gov\\\\DKMIROSHNIKOVALAB\\\\Lab Notebooks\\\\Ike\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g_df = SG_preprocess_tracks(fpath_list, r\"test005-1\", save_images=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hitips2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
